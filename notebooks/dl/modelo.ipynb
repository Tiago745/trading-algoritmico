{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a546866",
   "metadata": {},
   "source": [
    "# Modelo MLP para Previsão de Preços de Criptomoedas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e45948",
   "metadata": {},
   "source": [
    "## Importação das Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03575e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbfd25f",
   "metadata": {},
   "source": [
    "## PASSO 1: Carregar e Preparar os Dados\n",
    "\n",
    "**Objetivo:** Ler o arquivo CSV e garantir que ele esteja em ordem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1870108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega os dados do arquivo CSV\n",
    "df = pd.read_csv(r\"C:\\Users\\david\\Desktop\\trading-algoritmico\\data\\fechamentos\\SOLUSDT_1h_data.csv\")\n",
    "\n",
    "# Garante que a coluna 'timestamp' seja do tipo data e ordena os dados\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.sort_values('timestamp')\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Remove colunas com nomes \"Unnamed\".\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "print(f\"Dados carregados: {df.shape[0]} registros.\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a6fb8d",
   "metadata": {},
   "source": [
    "## PASSO 2: Preparar os Dados para o Modelo\n",
    "\n",
    "**Objetivo:** Transformar os dados brutos em um formato que a rede neural entenda (features e target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d86a29b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      7\u001b[39m SEQUENCE_LENGTH = \u001b[32m24\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# --- Criação das Features (X) e do Alvo (y) ---\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# O alvo (y) será binário: 1 se o preço subir, 0 se não.\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# `df[TARGET_COLUMN].shift(-1)` pega o preço de fechamento do *próximo* período.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m y = (\u001b[43mdf\u001b[49m[TARGET_COLUMN].shift(-\u001b[32m1\u001b[39m) > df[TARGET_COLUMN]).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# As features (X) serão os dados OHLCV.\u001b[39;00m\n\u001b[32m     15\u001b[39m X_raw = df[FEATURE_COLUMNS]\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Definição das Variáveis ---\n",
    "FEATURE_COLUMNS = ['open', 'high', 'low', 'close', 'volume']\n",
    "TARGET_COLUMN = 'close'\n",
    "\n",
    "# SEQUENCE_LENGTH: Quantos períodos olharemos para trás para prever o próximo.\n",
    "# Por exemplo, com 24, usaremos os dados das últimas 24 horas para fazer uma previsão.\n",
    "SEQUENCE_LENGTH = 24\n",
    "\n",
    "# --- Criação das Features (X) e do Alvo (y) ---\n",
    "# O alvo (y) será binário: 1 se o preço subir, 0 se não.\n",
    "# `df[TARGET_COLUMN].shift(-1)` pega o preço de fechamento do *próximo* período.\n",
    "y = (df[TARGET_COLUMN].shift(-1) > df[TARGET_COLUMN]).astype(int)\n",
    "\n",
    "# As features (X) serão os dados OHLCV.\n",
    "X_raw = df[FEATURE_COLUMNS]\n",
    "\n",
    "print(f\"Features definidas: {FEATURE_COLUMNS}\")\n",
    "print(f\"Sequence length: {SEQUENCE_LENGTH}\")\n",
    "print(f\"Shape dos dados brutos: {X_raw.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aa9e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Normalização dos Dados ---\n",
    "# Importante para redes neurais, pois ajuda na convergência do modelo\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_raw)\n",
    "\n",
    "print(f\"Dados normalizados. Shape: {X_scaled.shape}\")\n",
    "print(f\"Min: {X_scaled.min()}, Max: {X_scaled.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca6c935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Criação das Sequências ---\n",
    "# Cria sequências de dados para o modelo\n",
    "X_sequences, y_sequences = [], []\n",
    "for i in range(len(X_scaled) - SEQUENCE_LENGTH):\n",
    "    X_sequences.append(X_scaled[i : i + SEQUENCE_LENGTH])\n",
    "    y_sequences.append(y[i + SEQUENCE_LENGTH -1]) # O alvo corresponde ao final da sequência\n",
    "\n",
    "X = np.array(X_sequences)\n",
    "y = np.array(y_sequences)\n",
    "\n",
    "print(f\"Sequências criadas. X shape: {X.shape}, y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a343bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reshape do X para o MLP ---\n",
    "# O MLP espera uma entrada 2D, então precisa achatar as sequências\n",
    "num_samples = X.shape[0]\n",
    "num_features_flat = X.shape[1] * X.shape[2]\n",
    "X = X.reshape(num_samples, num_features_flat)\n",
    "\n",
    "print(f\"Shape de X (features): {X.shape}\")\n",
    "print(f\"Shape de y (alvo): {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802dca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Divisão em Treino e Teste ---\n",
    "# Divisão dos dados em treino e teste\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(X) * split_ratio)\n",
    "\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "print(f\"Amostras de treino: {len(X_train)}\")\n",
    "print(f\"Amostras de teste: {len(X_test)}\")\n",
    "print(f\"Distribuição do target no treino: {np.bincount(y_train)}\")\n",
    "print(f\"Distribuição do target no teste: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcce5f9e",
   "metadata": {},
   "source": [
    "## PASSO 3: Construir o Modelo (MLP)\n",
    "\n",
    "**Objetivo:** Definir a arquitetura da nossa rede neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b78139",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mSequential\u001b[49m()\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Camada de Entrada: Define o formato da nossa entrada\u001b[39;00m\n\u001b[32m      4\u001b[39m model.add(Input(shape=(num_features_flat,)))\n",
      "\u001b[31mNameError\u001b[39m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Camada de Entrada: Define o formato da nossa entrada\n",
    "model.add(Input(shape=(num_features_flat,)))\n",
    "\n",
    "# 1ª Camada Oculta: Primeira camada que aprende os padrões\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "\n",
    "# Camada de Dropout: Ajuda a prevenir overfitting\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "# 2ª Camada Oculta: Segunda camada para aprender padrões mais complexos\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "\n",
    "# Camada de Saída: Gera a previsão final\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ecf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compilação do Modelo ---\n",
    "# O modelo é compilado com o otimizador Adam e a função de perda binary_crossentropy, adequada para problemas de classificação binária\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Mostra um resumo da arquitetura do modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8796608",
   "metadata": {},
   "source": [
    "## PASSO 4: Treinar o Modelo\n",
    "\n",
    "**Objetivo:** Alimentar o modelo com os dados de treino para que ele aprenda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a2d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,  # epochs: Quantas vezes o modelo verá todo o conjunto de dados de treino.\n",
    "    batch_size=32,  # batch_size: Quantas amostras o modelo vê antes de atualizar seus pesos.\n",
    "    validation_data=(X_test, y_test),  # Dados para validar o modelo a cada época.\n",
    "    verbose=1 # Mostra uma barra de progresso.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ce3c99",
   "metadata": {},
   "source": [
    "## PASSO 5: Avaliar o Modelo\n",
    "\n",
    "**Objetivo:** Verificar o quão bem o modelo se saiu nos dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb305fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- PASSO 5: Avaliando o Modelo ---\")\n",
    "\n",
    "# Fazer previsões nos dados de teste. A saída será uma probabilidade\n",
    "probabilities = model.predict(X_test)\n",
    "\n",
    "# Converter probabilidades em classes (0 ou 1) usando um limiar de 0.5\n",
    "predictions = (probabilities > 0.5).astype(int)\n",
    "\n",
    "# Calcular e mostrar as métricas\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "report = classification_report(y_test, predictions, target_names=['Não Sobe', 'Sobe'])\n",
    "\n",
    "print(f\"Acurácia no Teste: {accuracy * 100:.2f}%\")\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070d3a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMatriz de Confusão:\")\n",
    "# Um mapa de calor para visualizar a matriz de confusão\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Não Sobe', 'Sobe'], yticklabels=['Não Sobe', 'Sobe'])\n",
    "plt.xlabel('Predito')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8a3de6",
   "metadata": {},
   "source": [
    "## PASSO 6: Visualizar o Treinamento\n",
    "\n",
    "**Objetivo:** Plotar gráficos para ver se o modelo aprendeu bem ou se teve overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa525db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Gráfico da Acurácia\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Acurácia de Treino')\n",
    "plt.plot(history.history['val_accuracy'], label='Acurácia de Validação')\n",
    "plt.title('Acurácia ao Longo das Épocas')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.legend()\n",
    "\n",
    "# Gráfico da Perda (Loss)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Perda de Treino')\n",
    "plt.plot(history.history['val_loss'], label='Perda de Validação')\n",
    "plt.title('Perda ao Longo das Épocas')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Perda')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01e0065",
   "metadata": {},
   "source": [
    "## PASSO 7: Salvar o Modelo\n",
    "\n",
    "**Objetivo:** Salvar o modelo treinado e o normalizador para uso futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbefc81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por enquanto não é necessário salvar o modelo\n",
    "MODEL_PATH = \"mlp_basic_model.h5\"\n",
    "SCALER_PATH = \"basic_scaler.pkl\"\n",
    "\n",
    "model.save(MODEL_PATH)\n",
    "joblib.dump(scaler, SCALER_PATH)\n",
    "\n",
    "print(f\"Modelo salvo em: {MODEL_PATH}\")\n",
    "print(f\"Normalizador salvo em: {SCALER_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310063f5",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "### Já integrado:\n",
    "\n",
    "1. **Carrega dados históricos**\n",
    "2. **Prepara os dados**\n",
    "3. **Constrói um MLP**\n",
    "4. **Treina o modelo**\n",
    "5. **Avalia o desempenho**\n",
    "6. **Visualiza o treinamento**\n",
    "7. **Salva o modelo**\n",
    "\n",
    "### Próximos Passos:\n",
    "- ENTENDER POR QUE O MODELO SÓ FALA QUE VAI SUBIR\n",
    "- Adicionar features técnicas, prepara-las e dar ao treino do modelo\n",
    "- Implementar validação cruzada temporal\n",
    "- Testar diferentes janelas temporais"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
